{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import base64\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import io\n",
    "import shutil\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import smtplib\n",
    "import pyodbc\n",
    "\n",
    "CD2_base_url = os.environ['CD2_base_url']\n",
    "CD2_client_id = os.environ['CD2_client_id']\n",
    "CD2_client_secret = os.environ['CD2_client_secret']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def les_access_token(logger):\n",
    "    # Hent access_token\n",
    "    requesturl = \"https://api-gateway.instructure.com/ids/auth/login\"\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    r = requests.request(\n",
    "        \"POST\",\n",
    "        requesturl,\n",
    "        data=payload,\n",
    "        auth=(CD2_client_id, CD2_client_secret)\n",
    "    )\n",
    "    if r.status_code == 200:\n",
    "        respons = r.json()\n",
    "        access_token = respons['access_token']\n",
    "        logger.info(f\"Henta access_token OK: {access_token}\")\n",
    "        return access_token\n",
    "    else:\n",
    "        logger.error(f\"Klarte ikkje å skaffe access_token, feil {r.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_logger(log_namn):\n",
    "    # opprett ein logger\n",
    "    logger = logging.getLogger('my_logger')\n",
    "    logger.setLevel(logging.DEBUG)  # Sett ønska loggnivå\n",
    "\n",
    "    # Opprett formatter\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # Opprett filhandler for å logge til fil (ein loggfil kvar dag)\n",
    "    file_handler = logging.FileHandler(log_namn)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    # Opprett konsollhandler for å logge til konsollen\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.DEBUG)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Legg til handlerne i loggeren\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hent_CD2_filar(innfil, token, svar, logger):\n",
    "    try:\n",
    "        requesturl = f\"{CD2_base_url}/dap/object/url\"\n",
    "        payload = f\"{svar['objects']}\"\n",
    "        payload = payload.replace('\\'', '\\\"')\n",
    "        headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "        logger.info(f\"Request: {requesturl} {payload}\")\n",
    "        respons = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        logger.info(f\"Response: {respons.status_code} {respons.reason}\")\n",
    "        respons.raise_for_status()\n",
    "        fil = respons.json()\n",
    "        logger.info(f\"Objects: {fil}\")\n",
    "        url = fil['urls'][innfil]['url']\n",
    "        logger.info(f\"URL: {url}\")\n",
    "        data = requests.request(\"GET\", url)\n",
    "        logger.info(f\"Response: {data.status_code} {data.reason}\")\n",
    "        buffer = io.BytesIO(data.content)\n",
    "        logger.info(f\"Buffer: {buffer}\")\n",
    "        with gzip.GzipFile(fileobj=buffer, mode='rb') as utpakka_fil:\n",
    "            utpakka_data = utpakka_fil.read().decode(\"utf-8\", errors='ignore')\n",
    "            # logger.info(f\"Data: {utpakka_data}\")\n",
    "        return utpakka_data\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def les_CD2_tabell(token, tabell, logger):\n",
    "    headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "    # sist_oppdatert = akv_finn_sist_oppdatert(tabell)\n",
    "    payload = '{\"format\": \"csv\"}' # % (sist_oppdatert)\n",
    "    requesturl = f\"{CD2_base_url}/dap/query/canvas/table/{tabell}/data\"\n",
    "    print(f\"Sender søk til {requesturl}\")\n",
    "    try:\n",
    "        r = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        r.raise_for_status()\n",
    "        respons = r.json()\n",
    "        id = respons['id']\n",
    "        vent = True\n",
    "        while vent:\n",
    "            requesturl2 = f\"{CD2_base_url}/dap//job/{id}\"\n",
    "            r2 = requests.request(\"GET\", requesturl2, headers=headers)\n",
    "            time.sleep(5)\n",
    "            respons2 = r2.json()\n",
    "            print(respons2)\n",
    "            if respons2['status'] == \"complete\":\n",
    "                vent = False\n",
    "                filar = respons2['objects']\n",
    "        dr_liste = []\n",
    "        print(filar)\n",
    "        for fil in filar:\n",
    "            data = io.StringIO(akv_hent_CD2_filar(fil['id'], token, respons2))\n",
    "            df = pd.read_csv(data, sep=\",\")\n",
    "            dr_liste.append(df)\n",
    "        alledata = pd.concat(df for df in dr_liste if not df.empty)\n",
    "        return alledata, sist_oppdatert, respons2['until']\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def akv_finn_sist_oppdatert(tabell):\n",
    "    \"\"\"\n",
    "    Return the latest update time for the given table from the akv_sist_oppdatert table.\n",
    "    \"\"\"\n",
    "    conn_str = os.environ[\"Connection_SQL\"] \n",
    "    try:\n",
    "        with pyodbc.connect(conn_str) as connection:\n",
    "            cursor = connection.cursor()\n",
    "            print(connection)\n",
    "            query = \"\"\"\n",
    "            SELECT [sist_oppdatert] FROM [dbo].[akv_sist_oppdatert]\n",
    "            WHERE [tabell] = ?\n",
    "            \"\"\"\n",
    "            cursor.execute(query, (tabell,))\n",
    "            row = cursor.fetchone()\n",
    "            print(row)\n",
    "            if row:\n",
    "                print(\"Har henta frå Azure\")\n",
    "                if tabell == \"web_logs\":\n",
    "                    return (datetime.now() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "                else:\n",
    "                    return row[0].isoformat() + \"Z\"\n",
    "            else:\n",
    "                print(\"Har ikkje henta frå Azure\")\n",
    "                if tabell == \"web_logs\":\n",
    "                    return (datetime.now() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "                else:\n",
    "                    return (date.today() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "    except pyodbc.Error as exc:\n",
    "        print(\"Har ikkje henta frå Azure\")\n",
    "        if tabell == \"web_logs\":\n",
    "            return (datetime.now() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "        else:\n",
    "            return (datetime.today() - timedelta(days=1)).isoformat() + \"Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabell = \"enrollments\"\n",
    "logger = lag_logger(f'loggfil-{tabell}.log')\n",
    "token = les_access_token(logger)\n",
    "# data = les_CD2_tabell(token, tabell, logger)\n",
    "headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "sist_oppdatert = akv_finn_sist_oppdatert(tabell)\n",
    "sist_oppdatert = \"2025-05-01T01:00:00Z\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = '{\"format\": \"csv\", \"since\": \\\"%s\\\"}' % (sist_oppdatert)\n",
    "requesturl = f\"{CD2_base_url}/dap/query/canvas/table/{tabell}/data\"\n",
    "print(f\"Sender søk til {requesturl}\")\n",
    "# try:\n",
    "r = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "r.raise_for_status()\n",
    "respons = r.json()\n",
    "id = respons['id']\n",
    "vent = True\n",
    "while vent:\n",
    "    requesturl2 = f\"{CD2_base_url}/dap//job/{id}\"\n",
    "    r2 = requests.request(\"GET\", requesturl2, headers=headers)\n",
    "    time.sleep(5)\n",
    "    respons2 = r2.json()\n",
    "    print(respons2)\n",
    "    if respons2['status'] == \"complete\":\n",
    "        vent = False\n",
    "        filar = respons2['objects']\n",
    "dr_liste = []\n",
    "print(filar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fil in filar:\n",
    "    logger.info(f\"Henter fil {fil['id']}\")\n",
    "    data = io.StringIO(hent_CD2_filar(fil['id'], token, respons2, logger))\n",
    "    df = pd.read_csv(data, sep=\",\")\n",
    "    dr_liste.append(df)\n",
    "alledata = pd.concat(df for df in dr_liste if not df.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alledata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alledata.iloc[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lagre data til fil\n",
    "Den følgjande koden vil bli endra frå gang til gang; den bruker eg for å ta ut dei data som er interessante i kvart tilfelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alledata[['value.user_id', 'value.course_id', 'value.created_at', 'value.workflow_state', 'value.updated_at', 'value.last_activity_at', 'value.type']].to_csv(\"enrollments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
